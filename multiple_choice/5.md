# What is information?
1. Surprise!
1. The number of bits a file occupies
1. Knowledge, measured in length of white beard
1. Total number of published papers

# Imagine a process with 2 possible outcomes (p₂ = 1-p₁). The case of highest entropy is
1. p₁ = 1/2
1. p₁ = 1
1. p₁ = 1/√2
1. For only 2 outcomes entropy is the same for any p₁ value

# Why does the scaling of the generalized entropy of a finite dataset break at small scales?
1. The fine structure of a chaotic set cannot be resolved with 64-bit numbers
1. Below a minimum scale δ the entropy saturates to maximum value
1. Below a minimum scale δ the entropy saturates to minimum value
1. Trick question, the scaling does not break

# We obtain numbers from uniform random number generator and make two-dimensional vectors with them. In the limit of creating infinite vectors, the resulting dataset will have fractal dimension of
1. ∈ [0, 1)
1. Exactly = 1
1. ∈ (1, 2)
1. Exactly = 2

# The fractal boundary of Fig. 5.4 (which comes from a four dimensional system) has fractal dimension in the range
1. [0, 1]
1. (1, 2]
1. (2, 3]
1. (3, 4]
